{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the raw dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('data/master_data/john_hopkins_research.csv')\n",
    "raw_df.drop('Unnamed: 0', axis= 1, inplace= True)\n",
    "\n",
    "## make certain Last Update is datetime\n",
    "raw_df['Last Update'] = pd.to_datetime(raw_df['Last Update'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df = raw_df[raw_df['Country/Region'] == 'US']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the US df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "# thank you to @kinghelix and @trevormarburger for this idea\n",
    "abbrev_us_state = dict(map(reversed, us_state_abbrev.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_admin(combined_key):\n",
    "    if pd.isnull(combined_key):\n",
    "        county = np.nan\n",
    "    else:\n",
    "        county = combined_key.split(',')[0]\n",
    "    return county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_state(state):\n",
    "    if 'D.C.' in state or 'U.S.' in state:\n",
    "        state = state\n",
    "    elif '(From Diamond Princess)' in state:\n",
    "        if ',' in state:\n",
    "            state = abbrev_us_state[state.split('(')[0].split(',')[-1][1:-1]]\n",
    "        else:\n",
    "            state = 'Diamond Princess'\n",
    "    elif ',' in state:\n",
    "        state = abbrev_us_state[state.split(',')[-1].replace(' ', '')]\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "us_df['Admin2'] = us_df['Combined_Key'].apply(get_admin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "us_df['Province/State'] = us_df['Province/State'].apply(clean_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "### US at the state level\n",
    "### TODO: group by after extracting data\n",
    "us_df['Date'] = us_df['Last Update'].dt.date\n",
    "us_states = us_df.groupby(['Province/State', 'Date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'Alaska', 'American Samoa', 'Arizona', 'Arkansas',\n",
       "       'California', 'Chicago', 'Colorado', 'Connecticut', 'Delaware',\n",
       "       'Diamond Princess', 'District of Columbia', 'Florida', 'Georgia',\n",
       "       'Grand Princess', 'Grand Princess Cruise Ship', 'Guam', 'Hawaii',\n",
       "       'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky',\n",
       "       'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n",
       "       'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska',\n",
       "       'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
       "       'North Carolina', 'North Dakota', 'Northern Mariana Islands',\n",
       "       'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Puerto Rico',\n",
       "       'Recovered', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
       "       'Tennessee', 'Texas', 'US', 'United States Virgin Islands', 'Utah',\n",
       "       'Vermont', 'Virgin Islands', 'Virgin Islands, U.S.', 'Virginia',\n",
       "       'Washington', 'Washington, D.C.', 'West Virginia', 'Wisconsin',\n",
       "       'Wuhan Evacuee', 'Wyoming'], dtype='<U28')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(list(map(lambda x: x[0], us_states.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = us_states.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = us_states[['Province/State', 'Date', 'Confirmed', 'Deaths', 'Recovered', 'Active']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize US transformed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed = us_states[['Province/State']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed.rename(columns={'Province/State': 'State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['ConfirmedToDate'] = us_states['Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['Active'] = us_states['Active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['DeathToDate'] = us_states['Deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['RecoveredToDate'] = us_states['Recovered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['Date'] = us_states['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to help with transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_us_transformed = us_transformed.copy()\n",
    "def new_type(col):\n",
    "    copy_us_transformed['new'] = us_transformed.groupby('State').diff()[col]\n",
    "    \n",
    "    to_ret = np.where(np.isnan(copy_us_transformed['new']), \\\n",
    "                                         copy_us_transformed[col], \\\n",
    "                                         copy_us_transformed['new'])\n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_type(col):\n",
    "    return us_transformed.groupby('State').shift()[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate(col1, col2):\n",
    "    rate = []\n",
    "    for state in us_transformed['State'].unique():\n",
    "        tmp = us_transformed[us_transformed['State'] == state]\n",
    "        rate.extend(tmp[col1]/tmp[col2].shift())\n",
    "    return np.array(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_days_in(col, num=1):\n",
    "    return_array = np.array([])\n",
    "    for state in us_transformed['State'].unique():\n",
    "        temp_df = us_transformed[us_transformed['State'] == state].copy()\n",
    "        arr = np.cumsum(np.where(temp_df[col] > num, 1, 0))\n",
    "        return_array = np.append(return_array, arr)\n",
    "    return return_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(col, suffix):\n",
    "    \n",
    "    ### new cases\n",
    "    new_col = 'New' + suffix\n",
    "    us_transformed[new_col] = new_type(col)\n",
    "    \n",
    "    ### prev new cases\n",
    "    prev_new_col = 'Prev' + new_col\n",
    "    us_transformed[prev_new_col] = prev_type(new_col)\n",
    "    \n",
    "    ### cases growth\n",
    "    growth_col = 'GrowthRate' + suffix\n",
    "    us_transformed[growth_col] = get_rate(new_col, col)\n",
    "    \n",
    "    ### new cases two day avg\n",
    "    col_name_2_day_avg = new_col + \"2DayAvg\"\n",
    "    us_transformed[col_name_2_day_avg] = (us_transformed[new_col] + us_transformed[prev_new_col])/2\n",
    "    \n",
    "    ### 2 day cases growth\n",
    "    col_name = 'GrowthRate' + suffix + \"2DayAvg\"\n",
    "    us_transformed[col_name] = get_rate(col_name_2_day_avg, col)\n",
    "    \n",
    "    ### growth rate change\n",
    "    col_growth_change = growth_col + 'Change'\n",
    "    us_transformed[col_growth_change] = us_transformed.groupby('State').diff()[col_name]\n",
    "    \n",
    "    ### days to double\n",
    "    days_to_double = 'DaysToDouble' + suffix\n",
    "    us_transformed[days_to_double] = 0.72/us_transformed[growth_col]\n",
    "    \n",
    "    ### days to double 2 day average\n",
    "    days_to_double_2 = days_to_double + '2DayAvg'\n",
    "    us_transformed[days_to_double_2] = 0.72/us_transformed[col_name]\n",
    "    \n",
    "    ### days to double change\n",
    "    days_to_double_2_change = days_to_double_2 + 'Change'\n",
    "    us_transformed[days_to_double_2_change] = us_transformed.groupby('State').diff()[days_to_double_2]\n",
    "    \n",
    "    ### days in 1\n",
    "    daysin1 = 'Daysin1' + suffix\n",
    "    us_transformed[daysin1] = get_days_in(col, 1)\n",
    "    \n",
    "    ### days in 5\n",
    "    daysin5 = 'Daysin5' + suffix\n",
    "    us_transformed[daysin5] = get_days_in(col, 5)\n",
    "    \n",
    "    ### days in 100\n",
    "    daysin100 = 'Daysin100' + suffix\n",
    "    us_transformed[daysin100] = get_days_in(col, 100)\n",
    "    \n",
    "    \n",
    "    ### days in 250\n",
    "    daysin250 = 'Daysin250' + suffix\n",
    "    us_transformed[daysin250] = get_days_in(col, 250)\n",
    "    \n",
    "    \n",
    "    ### days in 1000\n",
    "    daysin1000 = 'Daysin1000' + suffix\n",
    "    us_transformed[daysin1000] = get_days_in(col, 1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['NewConfirmed'] = us_transformed.groupby('State').diff()['ConfirmedToDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['NewConfirmed'] = np.where(np.isnan(us_transformed['NewConfirmed']), \\\n",
    "                                         us_transformed['ConfirmedToDate'], \\\n",
    "                                         us_transformed['NewConfirmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['PrevNewConfirmed'] = us_transformed.groupby('State').shift()['NewConfirmed'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['GrowthRate'] = get_rate('NewConfirmed', 'ConfirmedToDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['GrowthRate'] = us_transformed['GrowthRate'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new confirmed two day average\n",
    "us_transformed['NewConfirmed2DayAvg'] = (us_transformed['NewConfirmed'] + us_transformed['PrevNewConfirmed'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### growth rate two day average\n",
    "us_transformed['GrowthRate2DayAvg'] = get_rate('NewConfirmed2DayAvg', 'ConfirmedToDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['GrowthRate2DayAvg'] = us_transformed['GrowthRate2DayAvg'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## growth rate change\n",
    "us_transformed['GrowthRateChange'] = us_transformed.groupby('State').diff()['GrowthRate2DayAvg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rule of 72\n",
    "us_transformed['DaysToDoubleNew'] = 0.72/us_transformed['GrowthRate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['DaysToDouble2DayAvgNew'] = 0.72/us_transformed['GrowthRate2DayAvg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['DaysToDouble2DayAvgNewChange'] = us_transformed.groupby('State').diff()['DaysToDouble2DayAvgNew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['Daysin1'] = get_days_in('ConfirmedToDate', 1)\n",
    "us_transformed['Daysin5'] = get_days_in('ConfirmedToDate', 5)\n",
    "us_transformed['Daysin100'] = get_days_in('ConfirmedToDate', 100)\n",
    "us_transformed['Daysin250'] = get_days_in('ConfirmedToDate', 250)\n",
    "us_transformed['Daysin1000'] = get_days_in('ConfirmedToDate', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Death Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform('DeathToDate', 'Deaths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed['Active'] = us_states['Active']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the US data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'transformed' not in os.listdir('data'):\n",
    "    os.mkdir('data/transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_transformed.to_csv('data/transformed/us_transformed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv('data/master_data/country_level/new_cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('data/master_data/country_level/new_deaths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_.melt(id_vars='date', value_name='NewConfirmed').rename(columns={'date':'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.melt(id_vars='date', value_name='NewDeaths').rename(columns={'date':'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_.merge(df_2, on=['Date', 'variable']).rename(columns={'variable':'Country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Country').sum().to_csv('data/transformed/current.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### TODO: Check new confirmed negative "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
